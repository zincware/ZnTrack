{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Optimization with Optuna\n",
    "\n",
    "In this example we will train a RandomForest model and optimize its parameters using [Optuna](https://optuna.readthedocs.io/en/stable/).\n",
    "This example is an adapted version from the Optuna [Basic Concept example](https://optuna.readthedocs.io/en/stable/#basic-concepts).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in /tmp/tmproi4g97y/.git/\n",
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n"
     ]
    }
   ],
   "source": [
    "# Setup temporary directory and initialize git and dvc\n",
    "from zntrack import config\n",
    "config.nb_name = 'parameter_optimization.ipynb'\n",
    "\n",
    "from zntrack.utils import cwd_temp_dir\n",
    "temp_dir = cwd_temp_dir()\n",
    "\n",
    "!git init\n",
    "!dvc init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "Our Workflow consists of multiple steps:\n",
    "- Download the dataset\n",
    "- Split into train / test data\n",
    "- Train a RandomForest model on the train data\n",
    "- Evaluate the model on the test data\n",
    "\n",
    "We want to optimize the `max_depth` of the Model and use the `Evaluate` Node to compute a score that Optuna optimizes.\n",
    "We will use DVC [Experiments](https://dvc.org/doc/start/experiments) to track each run.\n",
    "In combination with Optuna, this allows us not only to optimize the parameters but also easily store and access the trained models afterwards.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://mermaid.ink/img/pako:eNp1jz0PgjAQhv8KuVkG1InBCY2zsFmHCz2wSXslpdUYwn_3YpSwuF2e572vCVqvCUrorH-2dwwxayrFKrLg4qrg-ECbMJKC2w9vBZ99Gg33FUasKa7kTuQFWXt38oHGtdqLagIaboTXgzVruc3zwye0DPqCYmn_B3aKYQOOgkOj5ZVJcZYpiHdycnYppaYOk5V1imeJYoq-fnELZQyJNpAGLR9WBvuADsoO7UjzG6bTY5I?type=png)](https://mermaid.live/edit#pako:eNp1jz0PgjAQhv8KuVkG1InBCY2zsFmHCz2wSXslpdUYwn_3YpSwuF2e572vCVqvCUrorH-2dwwxayrFKrLg4qrg-ECbMJKC2w9vBZ99Gg33FUasKa7kTuQFWXt38oHGtdqLagIaboTXgzVruc3zwye0DPqCYmn_B3aKYQOOgkOj5ZVJcZYpiHdycnYppaYOk5V1imeJYoq-fnELZQyJNpAGLR9WBvuADsoO7UjzG6bTY5I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna, sklearn, zntrack\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "\n",
    "class HousingDataSet(zntrack.Node):\n",
    "    \"\"\"Download and prepare the California housing dataset.\"\"\"\n",
    "    data = zntrack.dvc.outs(\"scikit_learn_data\")\n",
    "\n",
    "    def run(self) -> None:\n",
    "        _ = sklearn.datasets.fetch_california_housing(data_home=self.data, return_X_y=True)\n",
    "    \n",
    "    @property\n",
    "    def labels(self) -> dict:\n",
    "        _, labels = sklearn.datasets.fetch_california_housing(data_home=self.data, return_X_y=True)\n",
    "        return labels\n",
    "\n",
    "    @property\n",
    "    def features(self) -> dict:\n",
    "        features, _ = sklearn.datasets.fetch_california_housing(data_home=self.data, return_X_y=True)\n",
    "        return features\n",
    "\n",
    "class TrainTestSplit(zntrack.Node):\n",
    "    \"\"\"Split the dataset into train and test sets.\"\"\"\n",
    "    labels = zntrack.zn.deps()\n",
    "    features = zntrack.zn.deps()\n",
    "    seed = zntrack.zn.params(1234)\n",
    "\n",
    "    train_features = zntrack.zn.outs()\n",
    "    test_features = zntrack.zn.outs()\n",
    "    train_labels = zntrack.zn.outs()\n",
    "    test_labels = zntrack.zn.outs()\n",
    "\n",
    "    def run(self) -> None:\n",
    "        self.train_features, self.test_features, self.train_labels, self.test_labels = sklearn.model_selection.train_test_split(\n",
    "            self.features, self.labels, test_size=0.2, random_state=self.seed\n",
    "        )\n",
    "\n",
    "class RandomForest(zntrack.Node):\n",
    "    \"\"\"Train a random forest model.\"\"\"\n",
    "    train_features = zntrack.zn.deps()\n",
    "    train_labels = zntrack.zn.deps()\n",
    "    seed = zntrack.zn.params(1234)\n",
    "    max_depth = zntrack.zn.params()\n",
    "\n",
    "    model = zntrack.zn.outs()\n",
    "\n",
    "    def run(self) -> None:\n",
    "        self.model = sklearn.ensemble.RandomForestRegressor(random_state=self.seed, max_depth=self.max_depth)\n",
    "        self.model.fit(self.train_features, self.train_labels)\n",
    "\n",
    "class Evaluate(zntrack.Node):\n",
    "    \"\"\"Evaluate the model on a test set.\"\"\"\n",
    "    model = zntrack.zn.deps()\n",
    "    test_features = zntrack.zn.deps()\n",
    "    test_labels = zntrack.zn.deps()\n",
    "\n",
    "    score = zntrack.zn.metrics()\n",
    "\n",
    "    def run(self) -> None:\n",
    "        self.score = self.model.score(self.test_features, self.test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `zntrack.Project` to create our workflow as usual.\n",
    "To use DVC Experiments, we need to create an initial commit.\n",
    "Therefore, we run the project directly and make an initial git commit afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running DVC command: 'stage add --name HousingDataSet --force ...'\n",
      "Jupyter support is an experimental feature! Please save your notebook before running this command!\n",
      "Submit issues to https://github.com/zincware/ZnTrack.\n",
      "\u0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running DVC command: 'stage add --name TrainTestSplit --force ...'\n",
      "\u0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running DVC command: 'stage add --name RandomForest --force ...'\n",
      "\u0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running DVC command: 'stage add --name Evaluate --force ...'\n",
      "\u0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running DVC command: 'repro'\n"
     ]
    }
   ],
   "source": [
    "with zntrack.Project() as project:\n",
    "    data = HousingDataSet()\n",
    "    split = TrainTestSplit(labels=data.labels, features=data.features)\n",
    "    model = RandomForest(\n",
    "        train_features=split.train_features,\n",
    "        train_labels=split.train_labels,\n",
    "        max_depth=2\n",
    "    )\n",
    "    evaluate = Evaluate(model.model, split.test_features, split.test_labels)\n",
    "\n",
    "project.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main (root-commit) ffdf249] initial commit\n",
      " 20 files changed, 1013 insertions(+)\n",
      " create mode 100644 .dvc/.gitignore\n",
      " create mode 100644 .dvc/config\n",
      " create mode 100644 .dvcignore\n",
      " create mode 100644 .gitignore\n",
      " create mode 100644 dvc.lock\n",
      " create mode 100644 dvc.yaml\n",
      " create mode 100644 nodes/Evaluate/score.json\n",
      " create mode 100644 nodes/RandomForest/.gitignore\n",
      " create mode 100644 nodes/TrainTestSplit/.gitignore\n",
      " create mode 100644 parameter_optimization.ipynb\n",
      " create mode 100644 params.yaml\n",
      " create mode 100644 src/Evaluate.py\n",
      " create mode 100644 src/HousingDataSet.py\n",
      " create mode 100644 src/RandomForest.py\n",
      " create mode 100644 src/TrainTestSplit.py\n",
      " create mode 100644 src/__pycache__/Evaluate.cpython-310.pyc\n",
      " create mode 100644 src/__pycache__/HousingDataSet.cpython-310.pyc\n",
      " create mode 100644 src/__pycache__/RandomForest.cpython-310.pyc\n",
      " create mode 100644 src/__pycache__/TrainTestSplit.cpython-310.pyc\n",
      " create mode 100644 zntrack.json\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"initial commit\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize\n",
    "\n",
    "For Optuna we need to define an objective we want to optimize.\n",
    "We use the `project.create_experiment` API from ZnTrack to change the model parameter and return the score from the `Evaluate` stage as final metric to optimize.\n",
    "To later identify the experiments, we name them according to the `trial.number` from optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-05-26 08:39:40,066] A new study created in memory with name: no-name-2f8a2a93-14df-4524-9d5d-3dcf0c7d51eb\n",
      "[I 2023-05-26 08:39:57,325] Trial 0 finished with value: 0.8065939316861175 and parameters: {'max_depth': 25}. Best is trial 0 with value: 0.8065939316861175.\n",
      "[I 2023-05-26 08:40:14,116] Trial 1 finished with value: 0.8058760015942394 and parameters: {'max_depth': 20}. Best is trial 0 with value: 0.8065939316861175.\n",
      "[I 2023-05-26 08:40:28,567] Trial 2 finished with value: 0.7881269558646984 and parameters: {'max_depth': 11}. Best is trial 0 with value: 0.8065939316861175.\n",
      "[I 2023-05-26 08:40:43,036] Trial 3 finished with value: 0.7945585295544808 and parameters: {'max_depth': 12}. Best is trial 0 with value: 0.8065939316861175.\n",
      "[I 2023-05-26 08:41:02,693] Trial 4 finished with value: 0.8062700623107257 and parameters: {'max_depth': 31}. Best is trial 0 with value: 0.8065939316861175.\n",
      "[I 2023-05-26 08:41:22,189] Trial 5 finished with value: 0.8062920194093484 and parameters: {'max_depth': 24}. Best is trial 0 with value: 0.8065939316861175.\n",
      "[I 2023-05-26 08:41:39,771] Trial 6 finished with value: 0.8058263834426351 and parameters: {'max_depth': 29}. Best is trial 0 with value: 0.8065939316861175.\n",
      "[I 2023-05-26 08:41:53,515] Trial 7 finished with value: 0.7784655470784221 and parameters: {'max_depth': 10}. Best is trial 0 with value: 0.8065939316861175.\n",
      "[I 2023-05-26 08:42:06,208] Trial 8 finished with value: 0.7205004441414482 and parameters: {'max_depth': 7}. Best is trial 0 with value: 0.8065939316861175.\n",
      "[I 2023-05-26 08:42:17,725] Trial 9 finished with value: 0.6037173940095967 and parameters: {'max_depth': 4}. Best is trial 0 with value: 0.8065939316861175.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    with project.create_experiment(queue=False, name=f\"exp-{trial.number}\") as exp:\n",
    "        model.max_depth = trial.suggest_int(\"max_depth\", 2, 32)\n",
    "    \n",
    "    return exp[evaluate].score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "We can now investigate the best parameters via `study.best_params`.\n",
    "Additionally, because we used DVC experiments we can directly access the experiment with the best parameters, by the name we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 25}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = model.from_rev(rev=f\"exp-{study.best_trial.number}\")\n",
    "best_model.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.807 compared to initial score: 0.445\n"
     ]
    }
   ],
   "source": [
    "# we load split data into memory to compute the score.\n",
    "split.load()\n",
    "\n",
    "best_score = best_model.model.score(split.test_features, split.test_labels)\n",
    "# best_score == evaluate.from_rev(rev=f\"exp-{study.best_trial.number}\").score\n",
    "initial_score = evaluate.from_rev(rev=\"HEAD\").score\n",
    "print(f\"Best score: {best_score:.3f} compared to initial score: {initial_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zntrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
